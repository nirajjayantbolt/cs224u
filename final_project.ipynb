{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Niraj Jayant\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from operator import itemgetter\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "import sst\n",
    "from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
    "from torch_rnn_classifier import TorchRNNClassifier, TorchRNNClassifierModel\n",
    "from torch_rnn_classifier import TorchRNNClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants used in this project\n",
    "WINE_SRC_FILENAME = os.path.join(\n",
    "    \"data\", \"wine-reviews\", \"winemag-data-130k-v2.csv\")\n",
    "MIN_WINE_REVIEWS=100 # potentially change\n",
    "GLOVE_6B_50D_PATH = os.path.join(\n",
    "    \"data\", \"glove.6B\", \"glove.6B.50d.txt\")\n",
    "encoding=\"utf-8\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the initial data frame, we are going to be using just the description and the variety\n",
    "col_list=['description', 'variety']\n",
    "baseline_df = pd.read_csv(WINE_SRC_FILENAME, usecols=col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "variety_mapping = {'Shiraz': 'Syrah', \n",
    "                   'Pinot Gris': 'Pinot Grigio', 'Pinot Blanc': 'Pinot Grigio',  'Pinot Bianco' : 'Pinot Grigio', \n",
    "                   'Garnacha': 'Grenache',\n",
    "                   'Alvarinho' : 'Albariño',\n",
    "                    'Muscat' : 'Moscato',\n",
    "                   'Glera' : 'Prosecco',\n",
    "                   'Sauvignon': 'Sauvignon Blanc',\n",
    "                   'Blaufränkisch': 'Gamay',\n",
    "                   'Primitivo': 'Zinfandel',\n",
    "                   'Pinot Nero': 'Pinot Noir',\n",
    "                   'Tinta de Toro': 'Tempranillo', 'Tinto Fino': 'Tempranillo',\n",
    "                    'Monastrell': 'Mourvèdre',\n",
    "                   'Alvarinho': 'Albariño',\n",
    "                   'Rosato': 'Rosé',\n",
    "                  }\n",
    "\n",
    "def consolidate_varieties(variety_name):\n",
    "    if variety_name in variety_mapping:\n",
    "        return variety_mapping[variety_name]\n",
    "    else:\n",
    "        return variety_name\n",
    "\n",
    "# clean data is the entry point to cleaning our data frame. It removes low review wines, blends, consolidates varietals\n",
    "# note: for now, this wont do anything for descriptions. We will explore various improvements to descriptions\n",
    "def clean_data(input_df):\n",
    "    # assume caller does not want modified data - return new_copy\n",
    "    df = input_df.copy()\n",
    "    df = df[df.groupby('variety')['variety'].transform('count').ge(MIN_WINE_REVIEWS)]\n",
    "    filters = ['Blend', 'Cabernet Sauvignon-Merlot', 'Cabernet Sauvignon-Syrah', 'Meritage', 'G-S-M']\n",
    "    for filtered_variety in filters:\n",
    "        df = df[~df.variety.str.contains(filtered_variety)]\n",
    "    df['variety'] = df['variety'].apply(consolidate_varieties)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96433, 2)\n"
     ]
    }
   ],
   "source": [
    "cleansed_df = clean_data(baseline_df)\n",
    "print(cleansed_df.shape)\n",
    "# expectation that we have 96,433 examples here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.04650998, 0.0445559 , 0.04517794, 0.04417515, 0.04435921]),\n",
       " 'score_time': array([0.09912896, 0.09586215, 0.10755181, 0.09689999, 0.09530878]),\n",
       " 'test_score': array([0.00958214, 0.0093852 , 0.01049441, 0.00993733, 0.01040661]),\n",
       " 'train_score': array([0.00960455, 0.01070873, 0.01004368, 0.00946385, 0.01033728])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline - use the DummyClassifier with no additional cleaning\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "X = cleansed_df['description']\n",
    "y = cleansed_df['variety']\n",
    "dummy_clf = DummyClassifier(strategy=\"uniform\")\n",
    "\n",
    "cross_validate(dummy_clf, X, y, scoring='f1_macro', cv=skf,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay - that was pretty terrible. Now lets go ahead and do some cleansing of data as well\n",
    "def cleanse_descriptions(input_df):\n",
    "    df = input_df.copy()\n",
    "    df['description'] = df['description'].apply(normalize_text)\n",
    "    return df\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "punctuation_table = str.maketrans({key: None for key in string.punctuation})\n",
    "sno = SnowballStemmer('english')\n",
    "\n",
    "def normalize_text(raw_text):\n",
    "    try:\n",
    "        word_list = word_tokenize(raw_text)\n",
    "        normalized_sentence = []\n",
    "        for w in word_list:\n",
    "            try:\n",
    "                w = str(w)\n",
    "                lower_case_word = str.lower(w)\n",
    "                stemmed_word = sno.stem(lower_case_word)\n",
    "                no_punctuation = stemmed_word.translate(punctuation_table)\n",
    "                if len(no_punctuation) > 1 and no_punctuation not in stop_words:\n",
    "                    normalized_sentence.append(no_punctuation)\n",
    "            except:\n",
    "                continue\n",
    "        return normalized_sentence\n",
    "    except:\n",
    "        return ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleansed_df = cleanse_descriptions(cleansed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     [ripe, fruiti, wine, smooth, still, structur, ...\n",
       "2     [tart, snappi, flavor, lime, flesh, rind, domi...\n",
       "3     [pineappl, rind, lemon, pith, orang, blossom, ...\n",
       "4     [much, like, regular, bottl, 2012, come, acros...\n",
       "7     [dri, restrain, wine, offer, spice, profus, ba...\n",
       "8     [savori, dri, thyme, note, accent, sunnier, fl...\n",
       "9     [great, depth, flavor, fresh, appl, pear, frui...\n",
       "10    [soft, suppl, plum, envelop, oaki, structur, c...\n",
       "11    [dri, wine, veri, spici, tight, taut, textur, ...\n",
       "12    [slight, reduc, wine, offer, chalki, tannic, b...\n",
       "13    [domin, oak, oakdriven, aroma, includ, roast, ...\n",
       "14    [build, 150, year, six, generat, winemak, trad...\n",
       "15    [zesti, orang, peel, appl, note, abound, sprig...\n",
       "16    [bake, plum, molass, balsam, vinegar, cheesi, ...\n",
       "17    [raw, blackcherri, aroma, direct, simpl, good,...\n",
       "21    [sleek, mix, tart, berri, stem, herb, along, h...\n",
       "23    [wine, geneseo, district, offer, aroma, sour, ...\n",
       "24    [aroma, prune, blackcurr, toast, oak, carri, e...\n",
       "25    [oak, earth, intermingl, around, robust, aroma...\n",
       "27    [aroma, recal, ripe, dark, berri, toast, whiff...\n",
       "29    [clarksburg, becom, chenin, blanc, california,...\n",
       "30    [red, cherri, fruit, come, lace, light, tannin...\n",
       "34    [show, tart, green, gooseberri, flavor, simila...\n",
       "35    [mani, erath, 2010, vineyard, design, strong, ...\n",
       "37    [concentr, cabernet, offer, aroma, cure, meat,...\n",
       "38    [inki, color, wine, plump, aroma, ripe, fruit,...\n",
       "39    [part, natur, wine, movement, wine, made, orga...\n",
       "41    [stiff, tannic, wine, slowli, open, bring, bra...\n",
       "42    [festiv, wine, soft, ripe, fruit, acid, plus, ...\n",
       "43    [clean, brisk, mouthfeel, give, slight, oak, s...\n",
       "44    [berri, aroma, come, cola, herb, note, palat, ...\n",
       "47    [sweet, wine, flavor, white, sugar, orang, hon...\n",
       "48    [bottl, resembl, new, zealand, paradigm, sauvi...\n",
       "49    [soft, fruiti, generous, ripe, wine, full, jui...\n",
       "51    [much, differ, casa, silva, 2009, petit, verdo...\n",
       "55    [show, jellylik, flavor, orang, pear, earthi, ...\n",
       "56    [weighti, creami, medium, full, bodi, plenti, ...\n",
       "57    [touch, toast, almond, start, grillo, rev, gla...\n",
       "58    [light, herbal, strawberri, raspberri, aroma, ...\n",
       "59    [aroma, cranberri, barrel, spice, herb, follow...\n",
       "60    [syrupi, dens, wine, jammi, plum, vanilla, ind...\n",
       "61    [dens, hu, wine, aroma, black, plum, vanilla, ...\n",
       "62    [aroma, brood, note, barrel, spice, cherri, fl...\n",
       "64    [intrigu, touch, nose, bottl, jasmin, sea, sal...\n",
       "65    [warm, 2015, vintag, soft, fruiti, wine, open,...\n",
       "66    [soft, round, wine, ripe, generous, pear, melo...\n",
       "70    [aroma, vanilla, char, toast, lead, light, cre...\n",
       "71    [big, oak, defin, robust, dens, extract, red, ...\n",
       "72    [aroma, blackskin, fruit, leather, underbrush,...\n",
       "73    [juici, plum, raspberri, pencil, lead, lead, w...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleansed_df.description.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct \n",
    "\n",
    "glove_small = {}\n",
    "all_words = set(w for words in X for w in words)\n",
    "with open(GLOVE_6B_50D_PATH, \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode(encoding)\n",
    "        if (word in all_words):\n",
    "            nums=np.array(parts[1:], dtype=np.float32)\n",
    "            glove_small[word] = nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        if len(word2vec)>0:\n",
    "            self.dim=len(word2vec[next(iter(glove_small))])\n",
    "        else:\n",
    "            self.dim=0\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "\n",
    "    \n",
    "# and a tf-idf version of the same\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        if len(word2vec)>0:\n",
    "            self.dim=len(word2vec[next(iter(glove_small))])\n",
    "        else:\n",
    "            self.dim=0\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf, \n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleansed_df.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlu/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(X, size=100, window=5, min_count=5, workers=2)\n",
    "w2v = {w: vec for w, vec in zip(model.wv.index2word, model.wv.syn0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_nb = Pipeline([(\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), (\"multinomial nb\", MultinomialNB())])\n",
    "bern_nb = Pipeline([(\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), (\"bernoulli nb\", BernoulliNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.39923191, 1.35763001, 1.37009978, 1.3482151 , 1.37506628]),\n",
       " 'score_time': array([0.3747561 , 0.37871504, 0.38309503, 0.37148499, 0.36713576]),\n",
       " 'test_score': array([0.18856973, 0.19170563, 0.19295868, 0.19213188, 0.19431725]),\n",
       " 'train_score': array([0.23093638, 0.22985213, 0.23161311, 0.23003482, 0.22856989])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(mult_nb, X, y, scoring='f1_macro', cv=skf,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.37863398, 1.37427616, 1.38343811, 1.36535597, 1.37179708]),\n",
       " 'score_time': array([0.400985  , 0.39869285, 0.41357803, 0.39695597, 0.3951962 ]),\n",
       " 'test_score': array([0.14083293, 0.14302528, 0.14079188, 0.14711167, 0.14208191]),\n",
       " 'train_score': array([0.16245198, 0.16220059, 0.16173146, 0.16142293, 0.16140417])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(bern_nb, X, y, scoring='f1_macro', cv=skf,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "etree_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=200))])\n",
    "etree_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=200))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([58.02340817, 58.53746319, 57.82559299, 57.74854875, 58.61525416]),\n",
       " 'score_time': array([8.05409312, 7.59044194, 6.72545886, 6.78239799, 6.73230886]),\n",
       " 'test_score': array([0.31642043, 0.3344908 , 0.34937745, 0.31815292, 0.33891469]),\n",
       " 'train_score': array([0.9998726 , 0.99983804, 0.99970773, 0.99972947, 0.99986676])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(etree_w2v, X, y, scoring='f1_macro', cv=skf,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([68.36335588, 67.07578516, 69.75583506, 66.89327598, 66.52365017]),\n",
       " 'score_time': array([7.55213904, 7.47810292, 7.93639278, 7.52639914, 7.43071198]),\n",
       " 'test_score': array([0.32478018, 0.34318613, 0.35720333, 0.32587632, 0.35026093]),\n",
       " 'train_score': array([0.9998726 , 0.99983804, 0.99970773, 0.99972947, 0.99986676])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(etree_w2v_tfidf, X, y, scoring='f1_macro', cv=skf,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HfBertClassifierModel(nn.Module):\n",
    "    def __init__(self, n_classes, weights_name='bert-base-cased'):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.weights_name = weights_name\n",
    "        self.bert = BertModel.from_pretrained(self.weights_name)\n",
    "        self.hidden_dim = self.bert.embeddings.word_embeddings.embedding_dim\n",
    "        # The only new parameters -- the classifier layer:\n",
    "        self.W = nn.Linear(self.hidden_dim, self.n_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"Here, `X` is an np.array in which each element is a pair \n",
    "        consisting of an index into the BERT embedding and a 1 or 0\n",
    "        indicating whether the token is masked. The `fit` method will \n",
    "        train all these parameters against a softmax objective.\n",
    "        \n",
    "        \"\"\"\n",
    "        indices = X[: , 0, : ]\n",
    "        # Type conversion, since the base class insists on\n",
    "        # casting this as a FloatTensor, but we ned Long\n",
    "        # for `bert`.\n",
    "        indices = indices.long()\n",
    "        mask = X[: , 1, : ]      \n",
    "        (final_hidden_states, cls_output) = self.bert(\n",
    "            indices, attention_mask=mask)       \n",
    "        return self.W(cls_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HfBertClassifier(TorchShallowNeuralClassifier):\n",
    "    def __init__(self, weights_name='bert-base-cased', *args, **kwargs):\n",
    "        self.weights_name = weights_name\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.weights_name)\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def define_graph(self):\n",
    "        \"\"\"This method is used by `fit`. We override it here to use our\n",
    "        new BERT-based graph.\n",
    "        \n",
    "        \"\"\"\n",
    "        bert = HfBertClassifierModel(\n",
    "            self.n_classes_, weights_name=self.weights_name)\n",
    "        bert.train()\n",
    "        return bert\n",
    "    \n",
    "    def encode(self, X, max_length=None):\n",
    "        \"\"\"The `X` is a list of strings. We use the model's tokenizer\n",
    "        to get the indices and mask information.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list of [index, mask] pairs, where index is an int and mask\n",
    "        is 0 or 1.\n",
    "        \n",
    "        \"\"\"\n",
    "        data = self.tokenizer.batch_encode_plus(\n",
    "            X, \n",
    "            max_length=max_length,\n",
    "            add_special_tokens=True, \n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True)\n",
    "        indices = data['input_ids']\n",
    "        mask = data['attention_mask']\n",
    "        return [[i, m] for i, m in zip(indices, mask)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_fine_tune_mod = HfBertClassifier(\n",
    "    'bert-base-cased', \n",
    "    batch_size=16, # Crucial; large batches will eat up all your memory!\n",
    "    max_iter=4, \n",
    "    eta=0.00002)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.0058949 , 0.00813484, 0.00777006, 0.00820398, 0.00589013]),\n",
       " 'score_time': array([0., 0., 0., 0., 0.]),\n",
       " 'test_score': array([nan, nan, nan, nan, nan])}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(hf_fine_tune_mod, X, y, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    break\n",
    "    \n",
    "\n",
    "X_hf_str_train = [\" \".join(x) for x in X_train]\n",
    "X_hf_str_dev = [\" \".join(x) for x in X_test]\n",
    "X_hf_indices_train = hf_fine_tune_mod.encode(X_hf_str_train)\n",
    "\n",
    "X_hf_indices_dev = hf_fine_tune_mod.encode(X_hf_str_dev)\n",
    "%time _ = hf_fine_tune_mod.fit(X_hf_indices_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_fine_tune_preds = hf_fine_tune_mod.predict(X_hf_indices_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(hf_fine_tune_preds, y_hf_dev, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
